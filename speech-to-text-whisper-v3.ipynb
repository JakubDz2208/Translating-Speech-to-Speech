{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing pipeline that translate transcripted audio from Polish to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuba\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline, SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan, SpeechT5ForSpeechToSpeech\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, use_safetensors=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhisperForConditionalGeneration(\n",
       "  (model): WhisperModel(\n",
       "    (encoder): WhisperEncoder(\n",
       "      (conv1): Conv1d(128, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (embed_positions): Embedding(1500, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x WhisperEncoderLayer(\n",
       "          (self_attn): WhisperAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): WhisperDecoder(\n",
       "      (embed_tokens): Embedding(51866, 1280, padding_idx=50256)\n",
       "      (embed_positions): WhisperPositionalEmbedding(448, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x WhisperDecoderLayer(\n",
       "          (self_attn): WhisperAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): WhisperAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (proj_out): Linear(in_features=1280, out_features=51866, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(model_id, return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=5,\n",
    "    batch_size=16,\n",
    "    return_timestamps=False,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    "    use_fast=False,\n",
    "    generate_kwargs={\"language\": \"english\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "\n",
    "audio_queue = queue.Queue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio_saved(filename):\n",
    "    audio_data = np.fromfile(filename, dtype=np.int16)  # Load audio data from file\n",
    "    transcription = pipe(audio_data)\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_streaming = True\n",
    "\n",
    "def transcribe_audio(audio_data):\n",
    "    transcription = pipe(audio_data)\n",
    "    print(transcription)\n",
    "\n",
    "def record_and_transcribe_audio(record_seconds=5, channels=1, rate=16000):\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=pyaudio.paInt16,\n",
    "                    channels=channels,\n",
    "                    rate=rate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=rate * record_seconds,  # Adjust buffer size for desired chunk size\n",
    "                    input_device_index=None)  # Use default input device\n",
    "\n",
    "    print(\"Recording and transcribing...\")\n",
    "    while continue_streaming:\n",
    "        data = stream.read(rate * record_seconds)  # Read audio chunk from the microphone\n",
    "        audio_data = np.frombuffer(data, dtype=np.int16)  # Convert audio chunk to numpy array\n",
    "        transcribe_audio(audio_data)  # Transcribe audio chunk in real-time\n",
    "\n",
    "    print(\"Finished recording and transcribing.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "\n",
    "def record_audio(filename, record_seconds=5, channels=1, rate=16000):\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=channels,\n",
    "                    rate=rate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK,\n",
    "                    input_device_index=2)\n",
    "    print(\"Recording...\")\n",
    "    frames = []\n",
    "    for i in range(0, int(rate / CHUNK * record_seconds)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    print(\"Finished recording.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    wf = wave.open(filename, 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 Mapowanie dźwięku Microsoft - Input, MME (2 in, 0 out)\n",
      ">   1 Mikrofon (Virtual Desktop Audio, MME (2 in, 0 out)\n",
      "    2 Stream Mix (2 — Razer Seiren V2, MME (2 in, 0 out)\n",
      "    3 Playback Mix (2 — Razer Seiren , MME (2 in, 0 out)\n",
      "    4 Mikrofon (Voicemod Virtual Audi, MME (2 in, 0 out)\n",
      "    5 Mikrofon (Steam Streaming Micro, MME (2 in, 0 out)\n",
      "    6 Headset Microphone (Oculus Virt, MME (2 in, 0 out)\n",
      "    7 Mikrofon (Razer Barracuda X), MME (2 in, 0 out)\n",
      "    8 Microphone (2 — Razer Seiren V2, MME (2 in, 0 out)\n",
      "    9 Mapowanie dźwięku Microsoft - Output, MME (0 in, 2 out)\n",
      "<  10 Głośniki (Razer Barracuda X), MME (0 in, 2 out)\n",
      "   11 Słuchawki (Oculus Virtual Audio, MME (0 in, 2 out)\n",
      "   12 Sound Effects (2 — Razer Seiren, MME (0 in, 2 out)\n",
      "   13 Game (2 — Razer Seiren V2 X), MME (0 in, 2 out)\n",
      "   14 Głośniki (7.1 Surround Sound), MME (0 in, 2 out)\n",
      "   15 Głośniki (Steam Streaming Speak, MME (0 in, 2 out)\n",
      "   16 Realtek Digital Output (Realtek, MME (0 in, 2 out)\n",
      "   17 Aux 2 (2 — Razer Seiren V2 X), MME (0 in, 2 out)\n",
      "   18 Browser (2 — Razer Seiren V2 X), MME (0 in, 2 out)\n",
      "   19 KG251Q (NVIDIA High Definition , MME (0 in, 2 out)\n",
      "   20 Aux 3 (2 — Razer Seiren V2 X), MME (0 in, 2 out)\n",
      "   21 Głośniki (Steam Streaming Micro, MME (0 in, 2 out)\n",
      "   22 Linia (Voicemod Virtual Audio D, MME (0 in, 2 out)\n",
      "   23 Voice Chat (2 — Razer Seiren V2, MME (0 in, 2 out)\n",
      "   24 System (2 — Razer Seiren V2 X), MME (0 in, 2 out)\n",
      "   25 Aux 1 (2 — Razer Seiren V2 X), MME (0 in, 2 out)\n",
      "   26 Music (2 — Razer Seiren V2 X), MME (0 in, 2 out)\n",
      "   27 Headphones (2 — Razer Seiren V2, MME (0 in, 2 out)\n",
      "   28 Podstawowy sterownik przechwytywania dźwięku, Windows DirectSound (2 in, 0 out)\n",
      "   29 Mikrofon (Virtual Desktop Audio), Windows DirectSound (2 in, 0 out)\n",
      "   30 Stream Mix (2 — Razer Seiren V2 X), Windows DirectSound (2 in, 0 out)\n",
      "   31 Playback Mix (2 — Razer Seiren V2 X), Windows DirectSound (2 in, 0 out)\n",
      "   32 Mikrofon (Voicemod Virtual Audio Device (WDM)), Windows DirectSound (2 in, 0 out)\n",
      "   33 Mikrofon (Steam Streaming Microphone), Windows DirectSound (2 in, 0 out)\n",
      "   34 Headset Microphone (Oculus Virtual Audio Device), Windows DirectSound (2 in, 0 out)\n",
      "   35 Mikrofon (Razer Barracuda X), Windows DirectSound (2 in, 0 out)\n",
      "   36 Microphone (2 — Razer Seiren V2 X), Windows DirectSound (2 in, 0 out)\n",
      "   37 Podstawowy sterownik dźwięku, Windows DirectSound (0 in, 2 out)\n",
      "   38 Głośniki (Razer Barracuda X), Windows DirectSound (0 in, 2 out)\n",
      "   39 Słuchawki (Oculus Virtual Audio Device), Windows DirectSound (0 in, 2 out)\n",
      "   40 Sound Effects (2 — Razer Seiren V2 X), Windows DirectSound (0 in, 2 out)\n",
      "   41 Game (2 — Razer Seiren V2 X), Windows DirectSound (0 in, 2 out)\n",
      "   42 Głośniki (7.1 Surround Sound), Windows DirectSound (0 in, 8 out)\n",
      "   43 Głośniki (Steam Streaming Speakers), Windows DirectSound (0 in, 2 out)\n",
      "   44 Realtek Digital Output (Realtek(R) Audio), Windows DirectSound (0 in, 2 out)\n",
      "   45 Aux 2 (2 — Razer Seiren V2 X), Windows DirectSound (0 in, 2 out)\n",
      "   46 Browser (2 — Razer Seiren V2 X), Windows DirectSound (0 in, 2 out)\n",
      "   47 KG251Q (NVIDIA High Definition Audio), Windows DirectSound (0 in, 2 out)\n",
      "   48 Aux 3 (2 — Razer Seiren V2 X), Windows DirectSound (0 in, 2 out)\n",
      "   49 Głośniki (Steam Streaming Microphone), Windows DirectSound (0 in, 2 out)\n",
      "   50 Linia (Voicemod Virtual Audio Device (WDM)), Windows DirectSound (0 in, 2 out)\n",
      "   51 Voice Chat (2 — Razer Seiren V2 X), Windows DirectSound (0 in, 2 out)\n",
      "   52 System (2 — Razer Seiren V2 X), Windows DirectSound (0 in, 2 out)\n",
      "   53 Aux 1 (2 — Razer Seiren V2 X), Windows DirectSound (0 in, 2 out)\n",
      "   54 Music (2 — Razer Seiren V2 X), Windows DirectSound (0 in, 2 out)\n",
      "   55 Headphones (2 — Razer Seiren V2 X), Windows DirectSound (0 in, 2 out)\n",
      "   56 Słuchawki (Oculus Virtual Audio Device), Windows WASAPI (0 in, 2 out)\n",
      "   57 Sound Effects (2 — Razer Seiren V2 X), Windows WASAPI (0 in, 2 out)\n",
      "   58 Game (2 — Razer Seiren V2 X), Windows WASAPI (0 in, 2 out)\n",
      "   59 Głośniki (7.1 Surround Sound), Windows WASAPI (0 in, 8 out)\n",
      "   60 Głośniki (Steam Streaming Speakers), Windows WASAPI (0 in, 2 out)\n",
      "   61 Realtek Digital Output (Realtek(R) Audio), Windows WASAPI (0 in, 2 out)\n",
      "   62 Aux 2 (2 — Razer Seiren V2 X), Windows WASAPI (0 in, 2 out)\n",
      "   63 Browser (2 — Razer Seiren V2 X), Windows WASAPI (0 in, 2 out)\n",
      "   64 KG251Q (NVIDIA High Definition Audio), Windows WASAPI (0 in, 2 out)\n",
      "   65 Aux 3 (2 — Razer Seiren V2 X), Windows WASAPI (0 in, 2 out)\n",
      "   66 Głośniki (Steam Streaming Microphone), Windows WASAPI (0 in, 2 out)\n",
      "   67 Linia (Voicemod Virtual Audio Device (WDM)), Windows WASAPI (0 in, 2 out)\n",
      "   68 Voice Chat (2 — Razer Seiren V2 X), Windows WASAPI (0 in, 2 out)\n",
      "   69 System (2 — Razer Seiren V2 X), Windows WASAPI (0 in, 2 out)\n",
      "   70 Aux 1 (2 — Razer Seiren V2 X), Windows WASAPI (0 in, 2 out)\n",
      "   71 Music (2 — Razer Seiren V2 X), Windows WASAPI (0 in, 2 out)\n",
      "   72 Headphones (2 — Razer Seiren V2 X), Windows WASAPI (0 in, 2 out)\n",
      "   73 Głośniki (Razer Barracuda X), Windows WASAPI (0 in, 2 out)\n",
      "   74 Mikrofon (Virtual Desktop Audio), Windows WASAPI (1 in, 0 out)\n",
      "   75 Stream Mix (2 — Razer Seiren V2 X), Windows WASAPI (2 in, 0 out)\n",
      "   76 Playback Mix (2 — Razer Seiren V2 X), Windows WASAPI (2 in, 0 out)\n",
      "   77 Mikrofon (Voicemod Virtual Audio Device (WDM)), Windows WASAPI (2 in, 0 out)\n",
      "   78 Mikrofon (Steam Streaming Microphone), Windows WASAPI (2 in, 0 out)\n",
      "   79 Headset Microphone (Oculus Virtual Audio Device), Windows WASAPI (1 in, 0 out)\n",
      "   80 Mikrofon (Razer Barracuda X), Windows WASAPI (1 in, 0 out)\n",
      "   81 Microphone (2 — Razer Seiren V2 X), Windows WASAPI (1 in, 0 out)\n",
      "   82 Voice Chat (Voice Chat), Windows WDM-KS (0 in, 2 out)\n",
      "   83 System (System), Windows WDM-KS (0 in, 2 out)\n",
      "   84 Aux 3 (Aux 3), Windows WDM-KS (0 in, 2 out)\n",
      "   85 Sound Effects (Sound Effects), Windows WDM-KS (0 in, 2 out)\n",
      "   86 Game (Game), Windows WDM-KS (0 in, 2 out)\n",
      "   87 Playback Mix (Playback Mix), Windows WDM-KS (2 in, 0 out)\n",
      "   88 Microphone (Microphone), Windows WDM-KS (1 in, 0 out)\n",
      "   89 Aux 2 (Aux 2), Windows WDM-KS (0 in, 2 out)\n",
      "   90 Browser (Browser), Windows WDM-KS (0 in, 2 out)\n",
      "   91 Music (Music), Windows WDM-KS (0 in, 2 out)\n",
      "   92 Headphones (Headphones), Windows WDM-KS (0 in, 2 out)\n",
      "   93 Stream Mix (Stream Mix), Windows WDM-KS (2 in, 0 out)\n",
      "   94 Aux 1 (Aux 1), Windows WDM-KS (0 in, 2 out)\n",
      "   95 Output 1 (OCULUSVAD Wave Speaker Headphone), Windows WDM-KS (0 in, 2 out)\n",
      "   96 Output 2 (OCULUSVAD Wave Speaker Headphone), Windows WDM-KS (0 in, 2 out)\n",
      "   97 Input (OCULUSVAD Wave Speaker Headphone), Windows WDM-KS (2 in, 0 out)\n",
      "   98 Headset Microphone (OCULUSVAD Wave Microphone Headphone), Windows WDM-KS (1 in, 0 out)\n",
      "   99 Miks stereo (Realtek HD Audio Stereo input), Windows WDM-KS (2 in, 0 out)\n",
      "  100 Speakers (Realtek HD Audio output), Windows WDM-KS (0 in, 8 out)\n",
      "  101 Wejście liniowe (Realtek HD Audio Line input), Windows WDM-KS (2 in, 0 out)\n",
      "  102 Mikrofon (Realtek HD Audio Mic input), Windows WDM-KS (2 in, 0 out)\n",
      "  103 Headphones (Realtek HD Audio 2nd output), Windows WDM-KS (0 in, 2 out)\n",
      "  104 SPDIF Out (Realtek HDA SPDIF Out), Windows WDM-KS (0 in, 2 out)\n",
      "  105 Mikrofon (VDVAD Wave), Windows WDM-KS (1 in, 0 out)\n",
      "  106 Speakers (VDVAD Wave), Windows WDM-KS (0 in, 8 out)\n",
      "  107 Mikrofon (Steam Streaming Microphone Wave), Windows WDM-KS (8 in, 0 out)\n",
      "  108 Speakers (Steam Streaming Microphone Wave), Windows WDM-KS (0 in, 8 out)\n",
      "  109 Output (NVIDIA High Definition Audio), Windows WDM-KS (0 in, 2 out)\n",
      "  110 Speakers 1 (7.1 Surround Sound Wave Speaker Headphone), Windows WDM-KS (0 in, 8 out)\n",
      "  111 Speakers 2 (7.1 Surround Sound Wave Speaker Headphone), Windows WDM-KS (0 in, 2 out)\n",
      "  112 Input (7.1 Surround Sound Wave Speaker Headphone), Windows WDM-KS (8 in, 0 out)\n",
      "  113 Mikrofon (Voicemod VAD Wave), Windows WDM-KS (2 in, 0 out)\n",
      "  114 Line Out (Voicemod VAD Wave), Windows WDM-KS (0 in, 2 out)\n",
      "  115 Input (Steam Streaming Speakers Wave), Windows WDM-KS (8 in, 0 out)\n",
      "  116 Speakers (Steam Streaming Speakers Wave), Windows WDM-KS (0 in, 8 out)\n",
      "  117 Mikrofon (Razer Barracuda X), Windows WDM-KS (1 in, 0 out)\n",
      "  118 Głośniki (Razer Barracuda X), Windows WDM-KS (0 in, 2 out)\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "\n",
    "print(sd.query_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n"
     ]
    }
   ],
   "source": [
    "record_audio('test.wav', record_seconds=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = 'test.wav'\n",
    "audio_rec = transcribe_audio_saved(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In today's busy times it is worth to find a moment for a breath and reflection. The daily rush of life often pushes us with his speed, but we decide how we proceed with him Let's stop for a moment, listen to the sound of nature and take care of our health.\n"
     ]
    }
   ],
   "source": [
    "audio_text = audio_rec['text']\n",
    "\n",
    "print(audio_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "# Load your audio file first\n",
    "waveform, sample_rate = torchaudio.load(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speechbrain.pretrained import EncoderClassifier\n",
    "\n",
    "classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-xvect-voxceleb\", savedir=\"pretrained_models/spkrec-xvect-voxceleb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuba\\AppData\\Local\\Temp\\ipykernel_29984\\3326449900.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = torch.tensor(embeddings).unsqueeze(0)\n"
     ]
    }
   ],
   "source": [
    "embeddings = classifier.encode_batch(waveform)\n",
    "embeddings = torch.nn.functional.normalize(embeddings, dim=1)\n",
    "embeddings = embeddings.squeeze()\n",
    "embeddings = torch.tensor(embeddings).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SpeechT5ForSpeechToSpeech were not initialized from the model checkpoint at microsoft/speecht5_vc and are newly initialized: ['speecht5.encoder.prenet.pos_sinusoidal_embed.weights']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tts_processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "tts_model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
    "sts_model = SpeechT5ForSpeechToSpeech.from_pretrained(\"microsoft/speecht5_vc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "speaker_embedding = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "def text_to_speech(text):\n",
    "    inputs = tts_processor(text=text, return_tensors='pt')\n",
    "    inputs = inputs[\"input_ids\"]\n",
    "    speech = tts_model.generate_speech(inputs, speaker_embeddings=embeddings, vocoder=vocoder)\n",
    "    # inputs = processor(audio=speech, sampling_rate=16000, return_tensors=\"pt\")\n",
    "    sf.write(\"speech.wav\", speech.numpy(), samplerate=16000)\n",
    "    # speech = model.generate_speech(inputs[\"input_values\"], embeddings, vocoder=vocoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_speech(audio_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesiser = pipeline(\n",
    "    \"text-to-speech\", \n",
    "    model=tts_model,\n",
    "    tokenizer=tts_processor.tokenizer,\n",
    "    feature_extractor=tts_processor.feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpeechT5Processor:\n",
       "- feature_extractor: SpeechT5FeatureExtractor {\n",
       "  \"do_normalize\": false,\n",
       "  \"feature_extractor_type\": \"SpeechT5FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"fmax\": 7600,\n",
       "  \"fmin\": 80,\n",
       "  \"frame_signal_scale\": 1.0,\n",
       "  \"hop_length\": 16,\n",
       "  \"mel_floor\": 1e-10,\n",
       "  \"num_mel_bins\": 80,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0.0,\n",
       "  \"processor_class\": \"SpeechT5Processor\",\n",
       "  \"reduction_factor\": 2,\n",
       "  \"return_attention_mask\": true,\n",
       "  \"sampling_rate\": 16000,\n",
       "  \"win_function\": \"hann_window\",\n",
       "  \"win_length\": 64\n",
       "}\n",
       "\n",
       "- tokenizer: SpeechT5Tokenizer(name_or_path='microsoft/speecht5_tts', vocab_size=79, model_max_length=600, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t79: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
       "\t80: AddedToken(\"<ctc_blank>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_speech_from_pipeline(text):\n",
    "    speech = synthesiser(text, forward_params={\"speaker_embeddings\": speaker_embedding})\n",
    "\n",
    "    inputs = tts_processor(audio=speech['audio'], sampling_rate=speech['sampling_rate'], return_tensors=\"pt\")\n",
    "    \n",
    "    speech = sts_model.generate_speech(inputs['input_values'], embeddings, vocoder=vocoder)\n",
    "    speech_np = speech.squeeze().cpu().numpy()\n",
    "\n",
    "    sf.write(\"speech_pipe.wav\", speech.numpy(), samplerate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_speech_from_pipeline(audio_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
